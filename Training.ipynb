{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# DeepSeekers",
   "id": "ac8f9a28dbfd28f1"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-13T22:34:36.621277Z",
     "start_time": "2025-04-13T22:34:34.088459Z"
    }
   },
   "source": [
    "%matplotlib inline\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')  # Set a compatible backend\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Class to Load Heatmap and Tau Data",
   "id": "8c5372f30fc227c4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T22:34:36.632261Z",
     "start_time": "2025-04-13T22:34:36.628794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Class for loading heatmap and tau data\n",
    "class HeatmapTauData(Dataset):\n",
    "    def __init__(self, hdf5):\n",
    "        self.hdf5 = hdf5                            # Path to HDF5 file\n",
    "        self.file = h5py.File(hdf5, 'r')      # Open file in read only\n",
    "        self.ksz_maps = self.file[\"ksz_maps\"]       # Load heatmap\n",
    "        self.tau_values = self.file[\"tau_values\"]   # Load tau value\n",
    "        self.num_samples = self.ksz_maps.shape[0]   # Number of samples\n",
    "\n",
    "    # Function to get number of samples\n",
    "    def __len__(self):\n",
    "        return self.num_samples     # Return the number of samples\n",
    "\n",
    "    # Function to get a heat map and tau value at index\n",
    "    def __getitem__(self, index):\n",
    "        # Load the heatmap and tau at given index\n",
    "        heatmap = self.ksz_maps[index]\n",
    "        tauval = self.tau_values[index]\n",
    "\n",
    "        # Convert heatmap and tau to tensor\n",
    "        heatmap = torch.tensor(heatmap, dtype=torch.float32)\n",
    "        tauval = torch.tensor(tauval, dtype=torch.float32)\n",
    "\n",
    "        # Return the heatmap and tau\n",
    "        return heatmap, tauval"
   ],
   "id": "1c3f228cc09b271b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## CNN Model",
   "id": "be6bcb877aa0bbd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T22:34:36.645236Z",
     "start_time": "2025-04-13T22:34:36.640776Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# CNN Model\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        # Initialize base class\n",
    "        super(Model, self).__init__()\n",
    "        # Convolutional layer: 1 input 16 output\n",
    "        self.convo1 = torch.nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        # Max pooling to reduce to half\n",
    "        self.pool1 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # Convolutional layer: 16 input 32 output\n",
    "        self.convo2 = torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        # Max pooling to reduce to half\n",
    "        self.pool2 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # Fully connected layer 128 features\n",
    "        self.linear1 = torch.nn.Linear(32 * 256 * 256, 128)\n",
    "        # Output layer for the single tau value\n",
    "        self.linear2 = torch.nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.convo1(x)))\n",
    "        x = self.pool2(F.relu(self.convo2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ],
   "id": "4a2c4682eb802a23",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "20f6a980ebef75b0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T22:34:37.635332Z",
     "start_time": "2025-04-13T22:34:36.894509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the data\n",
    "dataset = HeatmapTauData(\"data/ten_snapshots.hdf5\")\n",
    "\n",
    "# Shuffle and batch the data set\n",
    "dataloader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "# Set the Gaussian blur\n",
    "blur = T.GaussianBlur(kernel_size=5, sigma=(1.0, 2.0))\n",
    "\n",
    "# Create the model, loss, and optimizer\n",
    "model = Model()\n",
    "loss = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001) # lr is learning rate 0.001 standard starting point\n",
    "\n",
    "# Normalize tau values between [0,1]\n",
    "tau_min = dataset.tau_values[:].min()\n",
    "tau_max = dataset.tau_values[:].max()\n",
    "\n",
    "# Variable to store losses\n",
    "losses = []"
   ],
   "id": "c02a97e734690747",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train the Model",
   "id": "cc0a814ca238cc9a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T22:34:47.274011Z",
     "start_time": "2025-04-13T22:34:37.667315Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Loop to train for 5 epochs\n",
    "for epoch in range(5):\n",
    "    # Set the model to train\n",
    "    model.train()\n",
    "    # Initialize total loss\n",
    "    totalLoss = 0.0\n",
    "\n",
    "    # print(f\"Epoch {epoch + 1}, Loss: {totalLoss:.4f}\")\n",
    "    # losses.append(totalLoss)\n",
    "\n",
    "    # Loop to iterate through batches\n",
    "    for batch in dataloader:\n",
    "        # Get the input and target\n",
    "        heatmaps, tauvals = batch\n",
    "        # Add channel dimension\n",
    "        heatmaps = heatmaps.unsqueeze(1)\n",
    "        # Apply the Gaussian blur\n",
    "        heatmaps = blur(heatmaps)\n",
    "        # Reshape tau values\n",
    "        tauvals = tauvals.view(-1, 1)\n",
    "\n",
    "        # Compute mean and std to normalize\n",
    "        mean = heatmaps.mean(dim=(2, 3), keepdim=True)\n",
    "        std = heatmaps.std(dim=(2, 3), keepdim=True)\n",
    "        heatmaps = (heatmaps - mean) / (std + 1e-8)\n",
    "\n",
    "        # Normalize tau values to [0,1]\n",
    "        tauvals = (tauvals - tau_min) / (tau_max - tau_min)\n",
    "\n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad() # Reset previous gradients to zero to not mess up calculations\n",
    "        # Forward pass\n",
    "        output = model(heatmaps)\n",
    "        # Compute the loss\n",
    "        iterationLoss = loss(output, tauvals)\n",
    "        # Backpropagation\n",
    "        iterationLoss.backward()\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate the loss\n",
    "        totalLoss += iterationLoss.item()\n",
    "\n",
    "    # Print loss at the end of each epoch\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {totalLoss:.4f}\")\n",
    "    losses.append(totalLoss)"
   ],
   "id": "ba3b001d40411dba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.2507\n",
      "Epoch 2, Loss: 2992.5876\n",
      "Epoch 3, Loss: 131.4828\n",
      "Epoch 4, Loss: 2.2592\n",
      "Epoch 5, Loss: 3.8992\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Print",
   "id": "447fd102936164f9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T22:34:47.512228Z",
     "start_time": "2025-04-13T22:34:47.279526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Plot training\n",
    "plt.plot(losses, marker='o')\n",
    "plt.title(\"Training Loss Over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE Loss\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "3fd5a5ff00fc2453",
   "outputs": [],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
